{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a5a655",
   "metadata": {
    "gather": {
     "logged": 1734858800411
    }
   },
   "outputs": [],
   "source": [
    "pip install langchain_community tiktoken langchain_openai langchainhub chromadb langchain openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aea477",
   "metadata": {
    "gather": {
     "logged": 1734858808045
    }
   },
   "outputs": [],
   "source": [
    "pip install bs4 langchain_chroma chromadb pysqlite3-binary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d414e6b",
   "metadata": {
    "gather": {
     "logged": 1734858808259
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from openai import AzureOpenAI\n",
    "os.environ[\"AZURE_OPENAI_KEY\"] = \"5985113856904cbba04bf152a1a13f86\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://genaisolution02.openai.azure.com/\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6288344",
   "metadata": {
    "gather": {
     "logged": 1734858814527
    }
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "import chromadb\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    # dimensions: Optional[int] = None, # Can specify dimensions with new text-embedding-3 models\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "    api_version=\"2024-07-01-preview\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    ")\n",
    "\n",
    "# Load, chunk and index the contents of the blog.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding = embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a9527",
   "metadata": {
    "gather": {
     "logged": 1734858822340
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# LLM\n",
    "from langchain.llms import AzureOpenAI\n",
    "llm = AzureOpenAI(model=\"gpt-35-turbo\",\n",
    "    #message =[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}],              \n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "    api_version=\"2024-07-01-preview\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    ,temperature=0.2,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109f901",
   "metadata": {
    "gather": {
     "logged": 1734858826839
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm1 = AzureChatOpenAI(\n",
    "    azure_deployment=\"gpt-35-turbo\",  \n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "    api_version=\"2024-07-01-preview\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    temperature=0.2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b094fb",
   "metadata": {
    "gather": {
     "logged": 1734858858192
    }
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm1\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"What is LLM fine tuning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dbb774",
   "metadata": {
    "gather": {
     "logged": 1734858884065
    }
   },
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"what is use of LLM? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101c8223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
